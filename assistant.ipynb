{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (1.26.4)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: tiktoken in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: openai in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.49.0-cp312-cp312-win_amd64.whl.metadata (162 kB)\n",
      "     ---------------------------------------- 0.0/162.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/162.3 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/162.3 kB ? eta -:--:--\n",
      "     ---------------------------- --------- 122.9/162.3 kB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 162.3/162.3 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: colorama in d:\\code\\hackaton-acpr\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/7.6 MB 3.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/7.6 MB 3.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/7.6 MB 4.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/7.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/7.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.0/7.6 MB 4.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/7.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.2/7.6 MB 3.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.2/7.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.4/7.6 MB 3.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.5/7.6 MB 3.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/7.6 MB 3.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.7/7.6 MB 3.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/7.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.1/7.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.1/7.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.1/7.6 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.2/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.2/7.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.5/7.6 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.6/7.6 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.6/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.7/7.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.8/7.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.9/7.6 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.0/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.2/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.2/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.3/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.4/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.6/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.7/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.9/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.0/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.3/7.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.6/7.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.8/7.6 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.9/7.6 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.1/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.3/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.7/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.9/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.1/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.1/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.2/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.6/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.9/7.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.2/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 3.1 MB/s eta 0:00:00\n",
      "Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl (187 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB 7.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.2 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.8 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "Using cached pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 pillow-10.2.0 pyparsing-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib tiktoken openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "\n",
    "for i in range(1, 8):\n",
    "    file_name = f\"./control_points/{i}.txt\"\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "            contents.append({'content': content})\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found.\")\n",
    "\n",
    "df = pd.DataFrame(contents, columns=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None \n",
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "df['content']= df[\"content\"].apply(lambda x : normalize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df[\"content\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df = df[df.n_tokens<8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_KEY\"] = \"7e93421f46cd4680831023addcb0f42d\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://francecentral-openai.openai.azure.com\"\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "def generate_embeddings(text, model=\"ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "df['embedding'] = df[\"content\"].apply(lambda x : generate_embeddings (x, model = \"ada-002\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_embedding(text, model=\"ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def search_docs(_df, user_query, top_n=4, to_print=True):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        model=\"ada-002\" # model should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model\n",
    "    )\n",
    "    _df[\"similarities\"] = _df[\"embedding\"].apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        _df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    if to_print:\n",
    "        display(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Point de contrôle 13 ======= # Catégorie : Aut...</td>\n",
       "      <td>323</td>\n",
       "      <td>[-0.00961134023964405, -0.00813981145620346, 0...</td>\n",
       "      <td>0.876890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Point de contrôle 23 ======= # Catégorie : Don...</td>\n",
       "      <td>384</td>\n",
       "      <td>[-0.011622103862464428, 0.007696355693042278, ...</td>\n",
       "      <td>0.767541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Point de contrôle 1 ======= # Catégorie : Tier...</td>\n",
       "      <td>143</td>\n",
       "      <td>[-0.017865363508462906, -0.019515523687005043,...</td>\n",
       "      <td>0.766913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Point de contrôle 4 ======= # Catégorie : Tier...</td>\n",
       "      <td>513</td>\n",
       "      <td>[-0.027942441403865814, -0.019337281584739685,...</td>\n",
       "      <td>0.761505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  n_tokens  \\\n",
       "6  Point de contrôle 13 ======= # Catégorie : Aut...       323   \n",
       "5  Point de contrôle 23 ======= # Catégorie : Don...       384   \n",
       "0  Point de contrôle 1 ======= # Catégorie : Tier...       143   \n",
       "3  Point de contrôle 4 ======= # Catégorie : Tier...       513   \n",
       "\n",
       "                                           embedding  similarities  \n",
       "6  [-0.00961134023964405, -0.00813981145620346, 0...      0.876890  \n",
       "5  [-0.011622103862464428, 0.007696355693042278, ...      0.767541  \n",
       "0  [-0.017865363508462906, -0.019515523687005043,...      0.766913  \n",
       "3  [-0.027942441403865814, -0.019337281584739685,...      0.761505  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = search_docs(df, \"Le token de l'utilisateur se retrouve régulièrement invalidé dans un délai de moins de 180 jours. \"\n",
    ", top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Objectif Principal : Le système doit permettre aux employés de l'ACPR d'accéder facilement aux documents normatifs relatifs à la supervision des activités des établissements financiers et de vérifier la conformité des phrases relatives aux produits financiers aux règlements en vigueur.\n",
    "1. Recherche Documentaire :\n",
    "•\tGérer les requêtes complexes en comprenant les relations entre les termes de recherche.\n",
    "•\tSi l’utilisateur ne parvient pas à trouver ce qu’il cherche, donne-lui des exemples de phrases à renseigner. Par exemple, donne-lui des mots clés ou des catégories. \n",
    "•\tSi tu lis une abréviation, que ce soit par l’utilisateur ou dans un document, et que tu ne la comprends pas, dis que tu ne comprends l’abréviation et cite-la. \n",
    "2. Accès aux Informations :\n",
    "•\tExtraire de manière précise les informations pertinentes des documents normatifs en réponse aux requêtes de l'utilisateur.\n",
    "•\tRestituer le contexte entourant une information pour une meilleure compréhension. Faire bien attention, à séparer la citation du texte normatif des informations contextuelles. Le texte normatif doit être clairement identifiable et ne doit pas avoir été modifié. \n",
    "3. Conformité des Phrases aux Règlements :\n",
    "•\tPermettre à l'utilisateur de soumettre une phrase relative à un produit financier et demander si elle est conforme aux règlements en vigueur.\n",
    "•\tAnalyser la phrase en utilisant les règles et les normes énoncées dans les documents normatifs.\n",
    "4. Gestion des Erreurs et Ambiguïtés :\n",
    "•\tGérer les situations où une requête est ambiguë ou incomplète en demandant des clarifications.\n",
    "•\tSi tu ne connais pas la réponse, dis-le et ne cherche pas à rajouter d’autres éléments à part des questions pour plus de précision.\n",
    "5. Mises à Jour Légales :\n",
    "•\tInformer les utilisateurs des modifications récentes dans la législation financière.\n",
    "6. Interaction Naturelle :\n",
    "•\tFavoriser une interaction conversationnelle naturelle avec l'utilisateur en comprenant le langage courant et en fournissant des réponses compréhensibles.\n",
    "•\tRéponds avec un langage formel est clair. Ce que tu écris doit pouvoir être présenté dans des rapports officiels. \n",
    "7. Assistance et Support :\n",
    "•\tFournir un support contextuel pour aider les utilisateurs à formuler des requêtes de manière efficace. Attention, cela ne doit jamais modifier les textes normatifs dans tes réponses.\n",
    "\n",
    "Points de contrôles sur lesquels baser la réponse : \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_DeploymentId\"] = \"gpt-35-turbo\"\n",
    "\n",
    "def generate_answer(prompt, system_prompt):\n",
    "  res = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DeploymentId\"),\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "  ).choices[0].message.content\n",
    "  return res\n",
    "\n",
    "def process_prompt(prompt):\n",
    "  res = search_docs(df, prompt, top_n=2, to_print=False)\n",
    "  sys_prompt = system_prompt + \"\\n\".join(res[\"content\"])\n",
    "  answer = generate_answer(prompt, sys_prompt)\n",
    "  return ({\"answer\": answer, \"docs\": res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = process_prompt(\"L'API a eu un niveau de disponibilité largement inférieur comparé à l'interface client sur septembre, est-ce conforme à la réglementation ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Selon l'article 67 de la DSP2, l'API doit fournir toutes les informations liées aux comptes de paiement sans discrimination par rapport à l'interface client. Si l'API a eu un niveau de disponibilité largement inférieur à celui de l'interface client, cela pourrait être considéré comme une non-conformité à la réglementation. Il est important de vérifier si cette situation est due à des limitations techniques ou à d'autres facteurs, et il est recommandé de contacter l'établissement concerné pour obtenir des explications et éventuellement demander les actions de remédiation nécessaires dans le respect des obligations réglementaires.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Point de contrôle 13 ======= # Catégorie : Aut...</td>\n",
       "      <td>323</td>\n",
       "      <td>[-0.00961134023964405, -0.00813981145620346, 0...</td>\n",
       "      <td>0.804161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Point de contrôle 23 ======= # Catégorie : Don...</td>\n",
       "      <td>384</td>\n",
       "      <td>[-0.011622103862464428, 0.007696355693042278, ...</td>\n",
       "      <td>0.803106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  n_tokens  \\\n",
       "6  Point de contrôle 13 ======= # Catégorie : Aut...       323   \n",
       "5  Point de contrôle 23 ======= # Catégorie : Don...       384   \n",
       "\n",
       "                                           embedding  similarities  \n",
       "6  [-0.00961134023964405, -0.00813981145620346, 0...      0.804161  \n",
       "5  [-0.011622103862464428, 0.007696355693042278, ...      0.803106  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"docs\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
